{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM0o-VAUByCp",
        "outputId": "683b0c2c-ae5e-459d-94ad-40938df8434f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/purview-x/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/purview-x/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/purview-x/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, MaxPooling1D, Bidirectional, LSTM, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Dense, Dropout, Concatenate, MultiHeadAttention, Add, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "import pickle\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import textstat\n",
        "\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxl7iPFaByCr",
        "outputId": "4cd6a535-9ebf-4328-86a0-c9c7252105c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original true_df columns: ['title', 'text', 'subject', 'date', 'label']\n",
            "Original fake_df columns: ['title', 'text', 'subject', 'date', 'label']\n",
            "New real1_df columns: ['id', 'title', 'text', 'url', 'top_img', 'authors', 'source', 'publish_date', 'movies', 'images', 'canonical_link', 'meta_data', 'label']\n",
            "New fake1_df columns: ['id', 'title', 'text', 'url', 'top_img', 'authors', 'source', 'publish_date', 'movies', 'images', 'canonical_link', 'meta_data', 'label']\n"
          ]
        }
      ],
      "source": [
        "# Load original datasets\n",
        "data_path = '/home/purview-x/Downloads/sproject/fake_news_prediction'\n",
        "true_df = pd.read_csv(f'{data_path}/Data-1/True.csv')\n",
        "fake_df = pd.read_csv(f'{data_path}/Data-1/Fake.csv')\n",
        "\n",
        "# Assign labels\n",
        "true_df['label'] = 1  # Real news\n",
        "fake_df['label'] = 0  # Fake news\n",
        "\n",
        "# Load new datasets\n",
        "new_data_path = '/home/purview-x/Downloads/sproject/newnews'\n",
        "real1_df = pd.read_csv(f'{new_data_path}/real1.csv')\n",
        "fake1_df = pd.read_csv(f'{new_data_path}/fake1.csv')\n",
        "\n",
        "# Assign labels to new datasets\n",
        "real1_df['label'] = 1  # Real news\n",
        "fake1_df['label'] = 0  # Fake news\n",
        "\n",
        "# Print column information to understand structure\n",
        "print(\"Original true_df columns:\", true_df.columns.tolist())\n",
        "print(\"Original fake_df columns:\", fake_df.columns.tolist())\n",
        "print(\"New real1_df columns:\", real1_df.columns.tolist())\n",
        "print(\"New fake1_df columns:\", fake1_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQCgZTjKByCs"
      },
      "outputs": [],
      "source": [
        "# Function to clean and standardize dataframes\n",
        "def clean_and_standardize(df):\n",
        "    # Remove rows with missing title or text\n",
        "    df = df.dropna(subset=['title', 'text'])\n",
        "\n",
        "    # Basic text cleaning\n",
        "    df['title'] = df['title'].str.strip()\n",
        "    df['text'] = df['text'].str.strip()\n",
        "\n",
        "    # Select only needed columns (match original dataset structure)\n",
        "    needed_columns = ['title', 'text', 'label']\n",
        "    existing_columns = [col for col in needed_columns if col in df.columns]\n",
        "\n",
        "    return df[existing_columns]\n",
        "\n",
        "# Clean and standardize all dataframes\n",
        "true_df_clean = clean_and_standardize(true_df)\n",
        "fake_df_clean = clean_and_standardize(fake_df)\n",
        "real1_df_clean = clean_and_standardize(real1_df)\n",
        "fake1_df_clean = clean_and_standardize(fake1_df)\n",
        "\n",
        "# Combine all datasets\n",
        "combined_df = pd.concat([true_df_clean, fake_df_clean, real1_df_clean, fake1_df_clean],\n",
        "                         ignore_index=True)\n",
        "\n",
        "# Check for duplicates (based on title and first 100 chars of text)\n",
        "combined_df['text_start'] = combined_df['text'].str[:100]\n",
        "combined_df = combined_df.drop_duplicates(subset=['title', 'text_start'])\n",
        "combined_df = combined_df.drop(columns=['text_start'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TAtdnYXByCs",
        "outputId": "3c9a578e-efd8-48f8-920e-d2ea7488d9a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class distribution after combining all datasets: label\n",
            "1    21040\n",
            "0    17989\n",
            "Name: count, dtype: int64\n",
            "Final balanced dataset shape: (35978, 3)\n"
          ]
        }
      ],
      "source": [
        "# Shuffle the dataset\n",
        "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "# Check class distribution\n",
        "class_counts = combined_df['label'].value_counts()\n",
        "print(f\"Class distribution after combining all datasets: {class_counts}\")\n",
        "\n",
        "# Balance the dataset if needed\n",
        "min_class_count = class_counts.min()\n",
        "df_balanced = pd.DataFrame()\n",
        "for label in combined_df['label'].unique():\n",
        "    df_class = combined_df[combined_df['label'] == label]\n",
        "    df_class = df_class.sample(min_class_count, random_state=42)\n",
        "    df_balanced = pd.concat([df_balanced, df_class])\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' URL ', text, flags=re.MULTILINE)\n",
        "    # Replace numbers with 'NUM'\n",
        "    text = re.sub(r'\\d+', ' NUM ', text)\n",
        "    # Remove special characters but keep punctuation for sentiment analysis\n",
        "    text = re.sub(r'[^\\w\\s.,!?]', ' ', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "final_df = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(f\"Final balanced dataset shape: {final_df.shape}\")\n",
        "\n",
        "# Add this line to define df\n",
        "df = final_df.copy()\n",
        "\n",
        "# Now this will work\n",
        "df['content'] = df['title'].fillna('') + ' [SEP] ' + df['text'].fillna('')\n",
        "df['content'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Save the combined dataset\n",
        "final_df.to_csv(f'{data_path}/combined_balanced_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZcYs7XWByCs",
        "outputId": "d4e63fc5-41c3-498d-d6c8-550e85731f58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset Statistics:\n",
            "Number of articles: 35978\n",
            "Average title length: 77.65 characters\n",
            "Average text length: 2430.77 characters\n",
            "Number of real news: 17989\n",
            "Number of fake news: 17989\n",
            "\n",
            "Sample of real news titles:\n",
            "['Factbox: Fed and presidential campaign: where candidates stand', \"Delrahim to be nominated to head U.S. Justice Department's Antitrust Division\", 'Iran sticks to key limits of nuclear deal: U.N. watchdog report']\n",
            "\n",
            "Sample of fake news titles:\n",
            "['FINALLY! Fed Up Princeton Students Fight Back Against Black Lives Matter Terrorists’ Demands', 'WOW! WOMAN TOTALLY FREAKS OUT At Sight Of Confederate Flag In Store…REAL OR FAKE OUTRAGE? [Video]', 'PEDOPHILE PIGS Send Teenage Migrant Boys To Surgery After Out-Of-Control Rape In Refugee Camps [VIDEO]']\n"
          ]
        }
      ],
      "source": [
        " # Basic statistics about the dataset\n",
        "print(\"\\nDataset Statistics:\")\n",
        "print(f\"Number of articles: {len(final_df)}\")\n",
        "print(f\"Average title length: {final_df['title'].str.len().mean():.2f} characters\")\n",
        "print(f\"Average text length: {final_df['text'].str.len().mean():.2f} characters\")\n",
        "print(f\"Number of real news: {len(final_df[final_df['label'] == 1])}\")\n",
        "print(f\"Number of fake news: {len(final_df[final_df['label'] == 0])}\")\n",
        "\n",
        "# Sample a few entries from each class\n",
        "print(\"\\nSample of real news titles:\")\n",
        "print(final_df[final_df['label'] == 1]['title'].sample(3, random_state=42).tolist())\n",
        "print(\"\\nSample of fake news titles:\")\n",
        "print(final_df[final_df['label'] == 0]['title'].sample(3, random_state=42).tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6YiLmi7ByCs"
      },
      "outputs": [],
      "source": [
        "# Create a more informative content field\n",
        "df['content'] = df['title'].fillna('') + ' [SEP] ' + df['text'].fillna('')\n",
        "df['content'] = df['content'].apply(clean_text)\n",
        "\n",
        "# Word Segmentation and Stop Word Removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_and_remove_stopwords(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    # Keep some important stopwords that might be relevant for fake news detection\n",
        "    important_words = {'not', 'no', 'nor', 'but', 'however', 'although', 'though'}\n",
        "    filtered_stop_words = stop_words - important_words\n",
        "    tokens = [word for word in tokens if word not in filtered_stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['processed_content'] = df['content'].apply(tokenize_and_remove_stopwords)\n",
        "\n",
        "# Feature Engineering - Add additional features\n",
        "sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHvV_I43ByCt",
        "outputId": "e3d29306-1a4e-44ba-934e-abb385ddab86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Additional features extracted: ['sentiment_pos', 'sentiment_neg', 'sentiment_neu', 'sentiment_compound', 'readability', 'grade_level', 'word_count', 'avg_word_length', 'special_char_ratio']\n"
          ]
        }
      ],
      "source": [
        "def extract_features(text):\n",
        "    # Sentiment features\n",
        "    sentiment = sia.polarity_scores(text)\n",
        "\n",
        "    # Readability features\n",
        "    readability = textstat.flesch_reading_ease(text)\n",
        "    grade_level = textstat.flesch_kincaid_grade(text)\n",
        "\n",
        "    # Text statistics\n",
        "    word_count = len(text.split())\n",
        "    avg_word_length = sum(len(word) for word in text.split()) / max(1, word_count)\n",
        "\n",
        "    # Special character ratio\n",
        "    special_char_count = len(re.findall(r'[.,!?;:]', text))\n",
        "    special_char_ratio = special_char_count / max(1, len(text))\n",
        "\n",
        "    # Create feature dictionary\n",
        "    features = {\n",
        "        'sentiment_pos': sentiment['pos'],\n",
        "        'sentiment_neg': sentiment['neg'],\n",
        "        'sentiment_neu': sentiment['neu'],\n",
        "        'sentiment_compound': sentiment['compound'],\n",
        "        'readability': readability,\n",
        "        'grade_level': grade_level,\n",
        "        'word_count': word_count,\n",
        "        'avg_word_length': avg_word_length,\n",
        "        'special_char_ratio': special_char_ratio\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract additional features\n",
        "features_df = pd.DataFrame(df['content'].apply(extract_features).tolist())\n",
        "print(f\"Additional features extracted: {features_df.columns.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciiFiDohByCt"
      },
      "outputs": [],
      "source": [
        "# Tokenization with improved parameters\n",
        "max_length = 300  # Reduced max sequence length\n",
        "max_words = 15000  # Increased vocabulary size\n",
        "\n",
        "# Initialize and fit tokenizer\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(df['processed_content'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(df['processed_content'])\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "X_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "# TF-IDF Vectorization with improved parameters\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=3000, min_df=2, max_df=0.85, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['processed_content']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOYR9nNNByCt",
        "outputId": "977e7ea9-be02-47b8-e632-6e559ea5d77d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined feature matrix shape: (35978, 3009)\n"
          ]
        }
      ],
      "source": [
        "# Load GloVe Embeddings\n",
        "def load_glove_embeddings(glove_path):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index\n",
        "\n",
        "glove_path = '/home/purview-x/Downloads/sproject/glove.6B/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_path)\n",
        "\n",
        "embedding_dim = 300  # GloVe embedding dimension\n",
        "vocab_size = min(max_words, len(tokenizer.word_index) + 1)\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= vocab_size:\n",
        "        continue\n",
        "    embedding_vector = glove_embeddings.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# Create a feature matrix by combining TF-IDF and additional features\n",
        "X_features = np.hstack((X_tfidf, features_df.values))\n",
        "print(f\"Combined feature matrix shape: {X_features.shape}\")\n",
        "\n",
        "# Labels\n",
        "y = df['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfCGeBjmByCt"
      },
      "outputs": [],
      "source": [
        "# Define an improved model architecture\n",
        "def build_improved_model(vocab_size, embedding_dim, max_length, feature_dim):\n",
        "    # Input for sequences\n",
        "    sequence_input = Input(shape=(max_length,), name='sequence_input')\n",
        "\n",
        "    # Input for combined features\n",
        "    feature_input = Input(shape=(feature_dim,), name='feature_input')\n",
        "\n",
        "    # Embedding layer with GloVe\n",
        "    embedding = Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_length,\n",
        "        trainable=False,\n",
        "        name='embedding_layer'\n",
        "    )(sequence_input)\n",
        "\n",
        "    # Dropout after embedding (new)\n",
        "    embedding_dropout = Dropout(0.3, name='embedding_dropout')(embedding)\n",
        "\n",
        "    # SIMPLIFIED: Only TWO CNN branches instead of three\n",
        "    # First CNN Branch with BatchNormalization\n",
        "    conv1_branch1 = Conv1D(filters=64, kernel_size=5, activation='relu', padding='same',\n",
        "                          kernel_regularizer=l2(0.02), name='conv1_branch1')(embedding_dropout)\n",
        "    bn1_branch1 = BatchNormalization(name='bn1_branch1')(conv1_branch1)\n",
        "    pool1_branch1 = MaxPooling1D(pool_size=4, name='maxpool_branch1')(bn1_branch1)\n",
        "\n",
        "    # Second CNN Branch with BatchNormalization\n",
        "    conv1_branch2 = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
        "                          kernel_regularizer=l2(0.02), name='conv1_branch2')(embedding_dropout)\n",
        "    bn1_branch2 = BatchNormalization(name='bn1_branch2')(conv1_branch2)\n",
        "    pool1_branch2 = MaxPooling1D(pool_size=4, name='maxpool_branch2')(bn1_branch2)\n",
        "\n",
        "    # Concatenate the two branches\n",
        "    concatenated = Concatenate(name='concatenation_layer')([pool1_branch1, pool1_branch2])\n",
        "    dropout_after_concat = Dropout(0.4, name='dropout_after_concat')(concatenated)\n",
        "\n",
        "    # Simpler Bi-LSTM Layer with fewer units\n",
        "    bilstm = Bidirectional(LSTM(64, return_sequences=True, kernel_regularizer=l2(0.02)),\n",
        "                          name='bi_lstm_layer')(dropout_after_concat)\n",
        "\n",
        "    # Multi-head Attention Layer with fewer heads\n",
        "    mha = MultiHeadAttention(\n",
        "        num_heads=4,\n",
        "        key_dim=16,\n",
        "        name='multi_head_attention'\n",
        "    )(bilstm, bilstm)\n",
        "\n",
        "    # Add residual connection\n",
        "    mha_layer = Add(name='residual_connection')([bilstm, mha])\n",
        "    bn_after_mha = BatchNormalization(name='bn_after_mha')(mha_layer)\n",
        "\n",
        "    # Global pooling\n",
        "    global_pool = GlobalMaxPooling1D(name='global_pooling')(bn_after_mha)\n",
        "\n",
        "    # Feature processing\n",
        "    feature_dense = Dense(64, activation='relu', kernel_regularizer=l2(0.02), name='feature_dense')(feature_input)\n",
        "    bn_feature = BatchNormalization(name='bn_feature')(feature_dense)\n",
        "\n",
        "    # Combine sequence features with additional features\n",
        "    combined = Concatenate(name='data_transfer')([global_pool, bn_feature])\n",
        "\n",
        "    # Fully Connected Layers - Simplified\n",
        "    dense1 = Dense(128, activation='relu', kernel_regularizer=l2(0.02), name='fully_connected_1')(combined)\n",
        "    bn1 = BatchNormalization(name='bn_fc1')(dense1)\n",
        "    dropout1 = Dropout(0.6, name='dropout1')(bn1)\n",
        "\n",
        "    dense2 = Dense(64, activation='relu', kernel_regularizer=l2(0.02), name='fully_connected_2')(dropout1)\n",
        "    bn2 = BatchNormalization(name='bn_fc2')(dense2)\n",
        "    dropout2 = Dropout(0.6, name='dropout2')(bn2)\n",
        "\n",
        "    # Output Layer - binary classification\n",
        "    outputs = Dense(1, activation='sigmoid', name='output_layer')(dropout2)\n",
        "\n",
        "    # Create and compile model\n",
        "    model = Model(inputs=[sequence_input, feature_input], outputs=outputs)\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=0.0005),  # Reduced learning rate\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewhGPf86ByCu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def visualize_training_history(history, fold_num=None):\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Accuracy plot\n",
        "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax1.set_xlabel('Epochs')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    title = 'Accuracy Curves'\n",
        "    if fold_num:\n",
        "        title += f' - Fold {fold_num}'\n",
        "    ax1.set_title(title)\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Loss plot\n",
        "    ax2.plot(history.history['loss'], label='Training Loss')\n",
        "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_ylabel('Loss')\n",
        "    title = 'Loss Curves'\n",
        "    if fold_num:\n",
        "        title += f' - Fold {fold_num}'\n",
        "    ax2.set_title(title)\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if fold_num:\n",
        "        plt.savefig(f'training_history_fold_{fold_num}.png', dpi=300, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_additional_metrics(history, fold_num=None):\n",
        "    if 'auc' in history.history and 'precision' in history.history and 'recall' in history.history:\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "        # AUC plot\n",
        "        ax1.plot(history.history['auc'], label='Training AUC')\n",
        "        ax1.plot(history.history['val_auc'], label='Validation AUC')\n",
        "        ax1.set_xlabel('Epochs')\n",
        "        ax1.set_ylabel('AUC')\n",
        "        title = 'AUC Curves'\n",
        "        if fold_num:\n",
        "            title += f' - Fold {fold_num}'\n",
        "        ax1.set_title(title)\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "        # Precision plot\n",
        "        ax2.plot(history.history['precision'], label='Training Precision')\n",
        "        ax2.plot(history.history['val_precision'], label='Validation Precision')\n",
        "        ax2.set_xlabel('Epochs')\n",
        "        ax2.set_ylabel('Precision')\n",
        "        title = 'Precision Curves'\n",
        "        if fold_num:\n",
        "            title += f' - Fold {fold_num}'\n",
        "        ax2.set_title(title)\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "        # Recall plot\n",
        "        ax3.plot(history.history['recall'], label='Training Recall')\n",
        "        ax3.plot(history.history['val_recall'], label='Validation Recall')\n",
        "        ax3.set_xlabel('Epochs')\n",
        "        ax3.set_ylabel('Recall')\n",
        "        title = 'Recall Curves'\n",
        "        if fold_num:\n",
        "            title += f' - Fold {fold_num}'\n",
        "        ax3.set_title(title)\n",
        "        ax3.legend()\n",
        "        ax3.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        if fold_num:\n",
        "            plt.savefig(f'additional_metrics_fold_{fold_num}.png', dpi=300, bbox_inches='tight')\n",
        "        else:\n",
        "            plt.savefig('additional_metrics.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "def plot_confusion_matrix(model, X_val_seq, X_val_features, y_val, fold_num=None):\n",
        "    # Get predictions\n",
        "    y_pred_proba = model.predict([X_val_seq, X_val_features])\n",
        "    y_pred = (y_pred_proba > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    title = 'Confusion Matrix'\n",
        "    if fold_num:\n",
        "        title += f' - Fold {fold_num}'\n",
        "    plt.title(title)\n",
        "    plt.xticks([0.5, 1.5], ['Fake (0)', 'Real (1)'])\n",
        "    plt.yticks([0.5, 1.5], ['Fake (0)', 'Real (1)'])\n",
        "\n",
        "    if fold_num:\n",
        "        plt.savefig(f'confusion_matrix_fold_{fold_num}.png', dpi=300, bbox_inches='tight')\n",
        "    else:\n",
        "        plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    print(classification_report(y_val, y_pred, target_names=['Fake News', 'Real News']))\n",
        "\n",
        "def visualize_fold_results(fold_results):\n",
        "    # Extract metrics\n",
        "    folds = [result['fold'] for result in fold_results]\n",
        "    accuracies = [result['val_accuracy'] for result in fold_results]\n",
        "    aucs = [result['val_auc'] for result in fold_results]\n",
        "    precisions = [result['val_precision'] for result in fold_results]\n",
        "    recalls = [result['val_recall'] for result in fold_results]\n",
        "\n",
        "    # Calculate F1 scores\n",
        "    f1_scores = [2 * (p * r) / (p + r) if (p + r) > 0 else 0 for p, r in zip(precisions, recalls)]\n",
        "\n",
        "    # Create plots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0, 0].bar(folds, accuracies, color='royalblue')\n",
        "    axes[0, 0].set_title('Validation Accuracy by Fold')\n",
        "    axes[0, 0].set_xlabel('Fold')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].set_ylim(0, 1)\n",
        "    for i, acc in enumerate(accuracies):\n",
        "        axes[0, 0].text(i+1, acc+0.02, f'{acc:.4f}', ha='center')\n",
        "\n",
        "    # AUC\n",
        "    axes[0, 1].bar(folds, aucs, color='orangered')\n",
        "    axes[0, 1].set_title('Validation AUC by Fold')\n",
        "    axes[0, 1].set_xlabel('Fold')\n",
        "    axes[0, 1].set_ylabel('AUC')\n",
        "    axes[0, 1].set_ylim(0, 1)\n",
        "    for i, auc in enumerate(aucs):\n",
        "        axes[0, 1].text(i+1, auc+0.02, f'{auc:.4f}', ha='center')\n",
        "\n",
        "    # Precision & Recall\n",
        "    axes[1, 0].bar(folds, precisions, color='green', label='Precision')\n",
        "    axes[1, 0].bar(folds, recalls, color='purple', alpha=0.7, label='Recall')\n",
        "    axes[1, 0].set_title('Precision & Recall by Fold')\n",
        "    axes[1, 0].set_xlabel('Fold')\n",
        "    axes[1, 0].set_ylabel('Score')\n",
        "    axes[1, 0].set_ylim(0, 1)\n",
        "    axes[1, 0].legend()\n",
        "\n",
        "    # F1 Score\n",
        "    axes[1, 1].bar(folds, f1_scores, color='teal')\n",
        "    axes[1, 1].set_title('F1 Score by Fold')\n",
        "    axes[1, 1].set_xlabel('Fold')\n",
        "    axes[1, 1].set_ylabel('F1 Score')\n",
        "    axes[1, 1].set_ylim(0, 1)\n",
        "    for i, f1 in enumerate(f1_scores):\n",
        "        axes[1, 1].text(i+1, f1+0.02, f'{f1:.4f}', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary statistics\n",
        "    print(\"\\nCross-Validation Summary:\")\n",
        "    print(f\"Average Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
        "    print(f\"Average AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
        "    print(f\"Average Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n",
        "    print(f\"Average Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")\n",
        "    print(f\"Average F1 Score: {np.mean(f1_scores):.4f} ± {np.std(f1_scores):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# If you already have a trained model and want to visualize it:\n",
        "def visualize_best_model(best_model, X_test_seq, X_test_features, y_test):\n",
        "    # Evaluate on test set\n",
        "    test_results = best_model.evaluate([X_test_seq, X_test_features], y_test, verbose=1)\n",
        "    print(f\"Test Loss: {test_results[0]:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_results[1]:.4f}\")\n",
        "    print(f\"Test AUC: {test_results[2]:.4f}\")\n",
        "    print(f\"Test Precision: {test_results[3]:.4f}\")\n",
        "    print(f\"Test Recall: {test_results[4]:.4f}\")\n",
        "\n",
        "    # Confusion matrix and classification report\n",
        "    plot_confusion_matrix(best_model, X_test_seq, X_test_features, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNP2Qzc6ByCu",
        "outputId": "b1acc8e1-9f1a-4c8e-c5c3-6e833eca60ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training fold 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/purview-x/Downloads/sproject/sproject/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "I0000 00:00:1742530753.222415   12174 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21743 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1742530793.268811   31366 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7964 - auc: 0.8638 - loss: 11.0543 - precision: 0.7957 - recall: 0.7987\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99625, saving model to fake_news_model_fold_1.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 21ms/step - accuracy: 0.7965 - auc: 0.8639 - loss: 11.0503 - precision: 0.7958 - recall: 0.7988 - val_accuracy: 0.9962 - val_auc: 0.9992 - val_loss: 1.3815 - val_precision: 0.9978 - val_recall: 0.9947 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1077/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9860 - auc: 0.9971 - loss: 0.8676 - precision: 0.9867 - recall: 0.9853\n",
            "Epoch 2: val_accuracy did not improve from 0.99625\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9860 - auc: 0.9971 - loss: 0.8664 - precision: 0.9867 - recall: 0.9853 - val_accuracy: 0.9960 - val_auc: 0.9991 - val_loss: 0.1865 - val_precision: 0.9958 - val_recall: 0.9961 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9875 - auc: 0.9968 - loss: 0.1974 - precision: 0.9907 - recall: 0.9842\n",
            "Epoch 3: val_accuracy improved from 0.99625 to 0.99639, saving model to fake_news_model_fold_1.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9875 - auc: 0.9968 - loss: 0.1973 - precision: 0.9907 - recall: 0.9842 - val_accuracy: 0.9964 - val_auc: 0.9991 - val_loss: 0.1216 - val_precision: 0.9978 - val_recall: 0.9950 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1077/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9877 - auc: 0.9958 - loss: 0.1658 - precision: 0.9904 - recall: 0.9850\n",
            "Epoch 4: val_accuracy improved from 0.99639 to 0.99666, saving model to fake_news_model_fold_1.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - accuracy: 0.9877 - auc: 0.9958 - loss: 0.1657 - precision: 0.9904 - recall: 0.9850 - val_accuracy: 0.9967 - val_auc: 0.9990 - val_loss: 0.1161 - val_precision: 0.9989 - val_recall: 0.9944 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9891 - auc: 0.9975 - loss: 0.1493 - precision: 0.9922 - recall: 0.9860\n",
            "Epoch 5: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9891 - auc: 0.9975 - loss: 0.1493 - precision: 0.9922 - recall: 0.9860 - val_accuracy: 0.9961 - val_auc: 0.9986 - val_loss: 0.1319 - val_precision: 0.9994 - val_recall: 0.9928 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9880 - auc: 0.9971 - loss: 0.1555 - precision: 0.9915 - recall: 0.9843\n",
            "Epoch 6: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9880 - auc: 0.9971 - loss: 0.1555 - precision: 0.9915 - recall: 0.9843 - val_accuracy: 0.9954 - val_auc: 0.9983 - val_loss: 0.1649 - val_precision: 0.9994 - val_recall: 0.9914 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9900 - auc: 0.9977 - loss: 0.1576 - precision: 0.9925 - recall: 0.9875\n",
            "Epoch 7: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9900 - auc: 0.9977 - loss: 0.1576 - precision: 0.9925 - recall: 0.9875 - val_accuracy: 0.9967 - val_auc: 0.9986 - val_loss: 0.1075 - val_precision: 0.9989 - val_recall: 0.9944 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9892 - auc: 0.9977 - loss: 0.1466 - precision: 0.9918 - recall: 0.9863\n",
            "Epoch 8: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9892 - auc: 0.9977 - loss: 0.1466 - precision: 0.9918 - recall: 0.9863 - val_accuracy: 0.9872 - val_auc: 0.9971 - val_loss: 0.1722 - val_precision: 0.9774 - val_recall: 0.9975 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9919 - auc: 0.9977 - loss: 0.1343 - precision: 0.9944 - recall: 0.9895\n",
            "Epoch 9: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9919 - auc: 0.9977 - loss: 0.1343 - precision: 0.9944 - recall: 0.9895 - val_accuracy: 0.9928 - val_auc: 0.9991 - val_loss: 0.1433 - val_precision: 0.9884 - val_recall: 0.9972 - learning_rate: 5.0000e-04\n",
            "Epoch 9: early stopping\n",
            "Restoring model weights from the end of the best epoch: 4.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9959 - auc: 0.9987 - loss: 0.1195 - precision: 0.9994 - recall: 0.9924\n",
            "\n",
            "Training fold 2/5\n",
            "Epoch 1/20\n",
            "\u001b[1m1077/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8193 - auc_1: 0.8859 - loss: 11.0185 - precision_1: 0.8218 - recall_1: 0.8142\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99528, saving model to fake_news_model_fold_2.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8196 - auc_1: 0.8862 - loss: 11.0026 - precision_1: 0.8222 - recall_1: 0.8145 - val_accuracy: 0.9953 - val_auc_1: 0.9993 - val_loss: 1.4080 - val_precision_1: 0.9967 - val_recall_1: 0.9939 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9850 - auc_1: 0.9970 - loss: 0.8863 - precision_1: 0.9878 - recall_1: 0.9824\n",
            "Epoch 2: val_accuracy did not improve from 0.99528\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9850 - auc_1: 0.9970 - loss: 0.8857 - precision_1: 0.9878 - recall_1: 0.9824 - val_accuracy: 0.9951 - val_auc_1: 0.9986 - val_loss: 0.1893 - val_precision_1: 0.9967 - val_recall_1: 0.9936 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1077/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9867 - auc_1: 0.9969 - loss: 0.1964 - precision_1: 0.9899 - recall_1: 0.9839\n",
            "Epoch 3: val_accuracy improved from 0.99528 to 0.99597, saving model to fake_news_model_fold_2.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9867 - auc_1: 0.9969 - loss: 0.1963 - precision_1: 0.9899 - recall_1: 0.9839 - val_accuracy: 0.9960 - val_auc_1: 0.9994 - val_loss: 0.1159 - val_precision_1: 0.9972 - val_recall_1: 0.9947 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9881 - auc_1: 0.9970 - loss: 0.1644 - precision_1: 0.9908 - recall_1: 0.9855\n",
            "Epoch 4: val_accuracy did not improve from 0.99597\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9881 - auc_1: 0.9970 - loss: 0.1644 - precision_1: 0.9908 - recall_1: 0.9855 - val_accuracy: 0.9960 - val_auc_1: 0.9980 - val_loss: 0.1222 - val_precision_1: 0.9992 - val_recall_1: 0.9928 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9892 - auc_1: 0.9973 - loss: 0.1544 - precision_1: 0.9913 - recall_1: 0.9869\n",
            "Epoch 5: val_accuracy improved from 0.99597 to 0.99611, saving model to fake_news_model_fold_2.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9892 - auc_1: 0.9973 - loss: 0.1544 - precision_1: 0.9913 - recall_1: 0.9869 - val_accuracy: 0.9961 - val_auc_1: 0.9988 - val_loss: 0.1304 - val_precision_1: 0.9980 - val_recall_1: 0.9942 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9883 - auc_1: 0.9974 - loss: 0.1679 - precision_1: 0.9902 - recall_1: 0.9862\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.99611 to 0.99653, saving model to fake_news_model_fold_2.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 14ms/step - accuracy: 0.9883 - auc_1: 0.9974 - loss: 0.1679 - precision_1: 0.9902 - recall_1: 0.9862 - val_accuracy: 0.9965 - val_auc_1: 0.9986 - val_loss: 0.1655 - val_precision_1: 0.9994 - val_recall_1: 0.9936 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9926 - auc_1: 0.9983 - loss: 0.1289 - precision_1: 0.9959 - recall_1: 0.9895\n",
            "Epoch 7: val_accuracy did not improve from 0.99653\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.9926 - auc_1: 0.9983 - loss: 0.1289 - precision_1: 0.9959 - recall_1: 0.9895 - val_accuracy: 0.9962 - val_auc_1: 0.9988 - val_loss: 0.0814 - val_precision_1: 0.9967 - val_recall_1: 0.9958 - learning_rate: 2.5000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1076/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9932 - auc_1: 0.9986 - loss: 0.0923 - precision_1: 0.9961 - recall_1: 0.9904\n",
            "Epoch 8: val_accuracy did not improve from 0.99653\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 13ms/step - accuracy: 0.9932 - auc_1: 0.9986 - loss: 0.0923 - precision_1: 0.9961 - recall_1: 0.9904 - val_accuracy: 0.9964 - val_auc_1: 0.9981 - val_loss: 0.0814 - val_precision_1: 0.9986 - val_recall_1: 0.9942 - learning_rate: 2.5000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9931 - auc_1: 0.9990 - loss: 0.0898 - precision_1: 0.9941 - recall_1: 0.9921\n",
            "Epoch 9: val_accuracy improved from 0.99653 to 0.99666, saving model to fake_news_model_fold_2.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.9931 - auc_1: 0.9990 - loss: 0.0898 - precision_1: 0.9941 - recall_1: 0.9921 - val_accuracy: 0.9967 - val_auc_1: 0.9989 - val_loss: 0.0775 - val_precision_1: 0.9978 - val_recall_1: 0.9956 - learning_rate: 2.5000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9929 - auc_1: 0.9989 - loss: 0.0874 - precision_1: 0.9950 - recall_1: 0.9910\n",
            "Epoch 10: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9929 - auc_1: 0.9989 - loss: 0.0874 - precision_1: 0.9950 - recall_1: 0.9910 - val_accuracy: 0.9936 - val_auc_1: 0.9979 - val_loss: 0.0888 - val_precision_1: 0.9997 - val_recall_1: 0.9875 - learning_rate: 2.5000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9938 - auc_1: 0.9988 - loss: 0.0865 - precision_1: 0.9960 - recall_1: 0.9916\n",
            "Epoch 11: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9938 - auc_1: 0.9988 - loss: 0.0865 - precision_1: 0.9960 - recall_1: 0.9916 - val_accuracy: 0.9908 - val_auc_1: 0.9995 - val_loss: 0.0917 - val_precision_1: 0.9854 - val_recall_1: 0.9964 - learning_rate: 2.5000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9937 - auc_1: 0.9987 - loss: 0.0821 - precision_1: 0.9952 - recall_1: 0.9922\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9937 - auc_1: 0.9987 - loss: 0.0822 - precision_1: 0.9952 - recall_1: 0.9922 - val_accuracy: 0.9964 - val_auc_1: 0.9980 - val_loss: 0.0888 - val_precision_1: 0.9997 - val_recall_1: 0.9931 - learning_rate: 2.5000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9945 - auc_1: 0.9993 - loss: 0.0754 - precision_1: 0.9958 - recall_1: 0.9932\n",
            "Epoch 13: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9945 - auc_1: 0.9993 - loss: 0.0754 - precision_1: 0.9958 - recall_1: 0.9932 - val_accuracy: 0.9967 - val_auc_1: 0.9986 - val_loss: 0.0577 - val_precision_1: 0.9997 - val_recall_1: 0.9936 - learning_rate: 1.2500e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9954 - auc_1: 0.9993 - loss: 0.0552 - precision_1: 0.9967 - recall_1: 0.9940\n",
            "Epoch 14: val_accuracy did not improve from 0.99666\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9954 - auc_1: 0.9993 - loss: 0.0552 - precision_1: 0.9967 - recall_1: 0.9940 - val_accuracy: 0.9257 - val_auc_1: 0.9949 - val_loss: 0.2499 - val_precision_1: 0.8709 - val_recall_1: 0.9994 - learning_rate: 1.2500e-04\n",
            "Epoch 14: early stopping\n",
            "Restoring model weights from the end of the best epoch: 9.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9968 - auc_1: 0.9988 - loss: 0.0780 - precision_1: 0.9972 - recall_1: 0.9964\n",
            "\n",
            "Training fold 3/5\n",
            "Epoch 1/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8176 - auc_2: 0.8863 - loss: 10.8746 - precision_2: 0.8102 - recall_2: 0.8237\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99569, saving model to fake_news_model_fold_3.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - accuracy: 0.8177 - auc_2: 0.8864 - loss: 10.8706 - precision_2: 0.8103 - recall_2: 0.8238 - val_accuracy: 0.9957 - val_auc_2: 0.9987 - val_loss: 1.2812 - val_precision_2: 0.9961 - val_recall_2: 0.9953 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9849 - auc_2: 0.9971 - loss: 0.7977 - precision_2: 0.9866 - recall_2: 0.9832\n",
            "Epoch 2: val_accuracy improved from 0.99569 to 0.99639, saving model to fake_news_model_fold_3.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9849 - auc_2: 0.9971 - loss: 0.7974 - precision_2: 0.9866 - recall_2: 0.9832 - val_accuracy: 0.9964 - val_auc_2: 0.9985 - val_loss: 0.1955 - val_precision_2: 0.9992 - val_recall_2: 0.9936 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9879 - auc_2: 0.9975 - loss: 0.1926 - precision_2: 0.9900 - recall_2: 0.9858\n",
            "Epoch 3: val_accuracy improved from 0.99639 to 0.99694, saving model to fake_news_model_fold_3.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9879 - auc_2: 0.9975 - loss: 0.1926 - precision_2: 0.9900 - recall_2: 0.9858 - val_accuracy: 0.9969 - val_auc_2: 0.9987 - val_loss: 0.1380 - val_precision_2: 0.9986 - val_recall_2: 0.9953 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9877 - auc_2: 0.9966 - loss: 0.1713 - precision_2: 0.9903 - recall_2: 0.9853\n",
            "Epoch 4: val_accuracy did not improve from 0.99694\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9877 - auc_2: 0.9966 - loss: 0.1713 - precision_2: 0.9903 - recall_2: 0.9853 - val_accuracy: 0.9967 - val_auc_2: 0.9993 - val_loss: 0.1383 - val_precision_2: 0.9972 - val_recall_2: 0.9961 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9891 - auc_2: 0.9975 - loss: 0.1545 - precision_2: 0.9914 - recall_2: 0.9869\n",
            "Epoch 5: val_accuracy improved from 0.99694 to 0.99722, saving model to fake_news_model_fold_3.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9891 - auc_2: 0.9975 - loss: 0.1545 - precision_2: 0.9914 - recall_2: 0.9869 - val_accuracy: 0.9972 - val_auc_2: 0.9987 - val_loss: 0.1409 - val_precision_2: 0.9994 - val_recall_2: 0.9950 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9884 - auc_2: 0.9968 - loss: 0.1651 - precision_2: 0.9912 - recall_2: 0.9855\n",
            "Epoch 6: val_accuracy did not improve from 0.99722\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9884 - auc_2: 0.9968 - loss: 0.1651 - precision_2: 0.9912 - recall_2: 0.9855 - val_accuracy: 0.9962 - val_auc_2: 0.9986 - val_loss: 0.1213 - val_precision_2: 0.9992 - val_recall_2: 0.9933 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9910 - auc_2: 0.9981 - loss: 0.1415 - precision_2: 0.9937 - recall_2: 0.9883\n",
            "Epoch 7: val_accuracy did not improve from 0.99722\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9910 - auc_2: 0.9981 - loss: 0.1415 - precision_2: 0.9937 - recall_2: 0.9883 - val_accuracy: 0.9965 - val_auc_2: 0.9982 - val_loss: 0.1138 - val_precision_2: 0.9997 - val_recall_2: 0.9933 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9911 - auc_2: 0.9979 - loss: 0.1367 - precision_2: 0.9941 - recall_2: 0.9881\n",
            "Epoch 8: val_accuracy did not improve from 0.99722\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9911 - auc_2: 0.9979 - loss: 0.1368 - precision_2: 0.9941 - recall_2: 0.9881 - val_accuracy: 0.9972 - val_auc_2: 0.9989 - val_loss: 0.1132 - val_precision_2: 0.9992 - val_recall_2: 0.9953 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9915 - auc_2: 0.9983 - loss: 0.1383 - precision_2: 0.9941 - recall_2: 0.9887\n",
            "Epoch 9: val_accuracy did not improve from 0.99722\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9915 - auc_2: 0.9983 - loss: 0.1383 - precision_2: 0.9941 - recall_2: 0.9887 - val_accuracy: 0.9969 - val_auc_2: 0.9984 - val_loss: 0.1205 - val_precision_2: 0.9997 - val_recall_2: 0.9942 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9915 - auc_2: 0.9985 - loss: 0.1324 - precision_2: 0.9931 - recall_2: 0.9897\n",
            "Epoch 10: val_accuracy did not improve from 0.99722\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9915 - auc_2: 0.9985 - loss: 0.1324 - precision_2: 0.9931 - recall_2: 0.9897 - val_accuracy: 0.9967 - val_auc_2: 0.9991 - val_loss: 0.0980 - val_precision_2: 0.9980 - val_recall_2: 0.9953 - learning_rate: 5.0000e-04\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 5.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9981 - auc_2: 0.9993 - loss: 0.1360 - precision_2: 0.9996 - recall_2: 0.9966\n",
            "\n",
            "Training fold 4/5\n",
            "Epoch 1/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8237 - auc_3: 0.8921 - loss: 10.6228 - precision_3: 0.8283 - recall_3: 0.8146\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99486, saving model to fake_news_model_fold_4.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - accuracy: 0.8238 - auc_3: 0.8921 - loss: 10.6187 - precision_3: 0.8284 - recall_3: 0.8147 - val_accuracy: 0.9949 - val_auc_3: 0.9988 - val_loss: 1.0686 - val_precision_3: 0.9955 - val_recall_3: 0.9942 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9856 - auc_3: 0.9968 - loss: 0.6833 - precision_3: 0.9877 - recall_3: 0.9832\n",
            "Epoch 2: val_accuracy improved from 0.99486 to 0.99639, saving model to fake_news_model_fold_4.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9856 - auc_3: 0.9968 - loss: 0.6829 - precision_3: 0.9877 - recall_3: 0.9832 - val_accuracy: 0.9964 - val_auc_3: 0.9990 - val_loss: 0.1762 - val_precision_3: 0.9989 - val_recall_3: 0.9939 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9880 - auc_3: 0.9969 - loss: 0.1919 - precision_3: 0.9903 - recall_3: 0.9858\n",
            "Epoch 3: val_accuracy did not improve from 0.99639\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9880 - auc_3: 0.9969 - loss: 0.1919 - precision_3: 0.9903 - recall_3: 0.9858 - val_accuracy: 0.9957 - val_auc_3: 0.9989 - val_loss: 0.1383 - val_precision_3: 0.9972 - val_recall_3: 0.9942 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1077/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9893 - auc_3: 0.9972 - loss: 0.1543 - precision_3: 0.9923 - recall_3: 0.9864\n",
            "Epoch 4: val_accuracy did not improve from 0.99639\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9893 - auc_3: 0.9972 - loss: 0.1544 - precision_3: 0.9923 - recall_3: 0.9864 - val_accuracy: 0.9962 - val_auc_3: 0.9992 - val_loss: 0.1201 - val_precision_3: 0.9994 - val_recall_3: 0.9930 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9882 - auc_3: 0.9967 - loss: 0.1592 - precision_3: 0.9913 - recall_3: 0.9849\n",
            "Epoch 5: val_accuracy did not improve from 0.99639\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 21ms/step - accuracy: 0.9882 - auc_3: 0.9967 - loss: 0.1592 - precision_3: 0.9913 - recall_3: 0.9849 - val_accuracy: 0.9896 - val_auc_3: 0.9989 - val_loss: 0.1515 - val_precision_3: 0.9838 - val_recall_3: 0.9956 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9908 - auc_3: 0.9983 - loss: 0.1458 - precision_3: 0.9921 - recall_3: 0.9893\n",
            "Epoch 6: val_accuracy did not improve from 0.99639\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.9908 - auc_3: 0.9983 - loss: 0.1458 - precision_3: 0.9921 - recall_3: 0.9893 - val_accuracy: 0.9964 - val_auc_3: 0.9988 - val_loss: 0.1235 - val_precision_3: 0.9994 - val_recall_3: 0.9933 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9899 - auc_3: 0.9969 - loss: 0.1482 - precision_3: 0.9921 - recall_3: 0.9876\n",
            "Epoch 7: val_accuracy improved from 0.99639 to 0.99694, saving model to fake_news_model_fold_4.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - accuracy: 0.9899 - auc_3: 0.9969 - loss: 0.1482 - precision_3: 0.9921 - recall_3: 0.9876 - val_accuracy: 0.9969 - val_auc_3: 0.9985 - val_loss: 0.1142 - val_precision_3: 0.9997 - val_recall_3: 0.9942 - learning_rate: 5.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9902 - auc_3: 0.9981 - loss: 0.1478 - precision_3: 0.9928 - recall_3: 0.9875\n",
            "Epoch 8: val_accuracy did not improve from 0.99694\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - accuracy: 0.9902 - auc_3: 0.9981 - loss: 0.1478 - precision_3: 0.9928 - recall_3: 0.9875 - val_accuracy: 0.9957 - val_auc_3: 0.9996 - val_loss: 0.0970 - val_precision_3: 0.9956 - val_recall_3: 0.9958 - learning_rate: 5.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9900 - auc_3: 0.9977 - loss: 0.1376 - precision_3: 0.9922 - recall_3: 0.9877\n",
            "Epoch 9: val_accuracy did not improve from 0.99694\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.9900 - auc_3: 0.9977 - loss: 0.1376 - precision_3: 0.9922 - recall_3: 0.9877 - val_accuracy: 0.9942 - val_auc_3: 0.9994 - val_loss: 0.1100 - val_precision_3: 0.9920 - val_recall_3: 0.9964 - learning_rate: 5.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9909 - auc_3: 0.9980 - loss: 0.1375 - precision_3: 0.9932 - recall_3: 0.9887\n",
            "Epoch 10: val_accuracy did not improve from 0.99694\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.9909 - auc_3: 0.9980 - loss: 0.1375 - precision_3: 0.9932 - recall_3: 0.9887 - val_accuracy: 0.9835 - val_auc_3: 0.9990 - val_loss: 0.1601 - val_precision_3: 0.9715 - val_recall_3: 0.9961 - learning_rate: 5.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9924 - auc_3: 0.9985 - loss: 0.1311 - precision_3: 0.9951 - recall_3: 0.9899\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.99694\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9924 - auc_3: 0.9985 - loss: 0.1311 - precision_3: 0.9951 - recall_3: 0.9899 - val_accuracy: 0.9965 - val_auc_3: 0.9982 - val_loss: 0.1342 - val_precision_3: 0.9997 - val_recall_3: 0.9933 - learning_rate: 5.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1077/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9927 - auc_3: 0.9987 - loss: 0.1099 - precision_3: 0.9948 - recall_3: 0.9906\n",
            "Epoch 12: val_accuracy did not improve from 0.99694\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 20ms/step - accuracy: 0.9927 - auc_3: 0.9987 - loss: 0.1098 - precision_3: 0.9948 - recall_3: 0.9906 - val_accuracy: 0.9962 - val_auc_3: 0.9991 - val_loss: 0.0673 - val_precision_3: 0.9997 - val_recall_3: 0.9928 - learning_rate: 2.5000e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9986 - auc_3: 0.9993 - loss: 0.1057 - precision_3: 1.0000 - recall_3: 0.9971\n",
            "\n",
            "Training fold 5/5\n",
            "Epoch 1/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8137 - auc_4: 0.8833 - loss: 11.0560 - precision_4: 0.8166 - recall_4: 0.8110\n",
            "Epoch 1: val_accuracy improved from -inf to 0.99527, saving model to fake_news_model_fold_5.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 22ms/step - accuracy: 0.8138 - auc_4: 0.8834 - loss: 11.0521 - precision_4: 0.8167 - recall_4: 0.8110 - val_accuracy: 0.9953 - val_auc_4: 0.9990 - val_loss: 1.4947 - val_precision_4: 0.9961 - val_recall_4: 0.9944 - learning_rate: 5.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9850 - auc_4: 0.9963 - loss: 0.9434 - precision_4: 0.9880 - recall_4: 0.9819\n",
            "Epoch 2: val_accuracy improved from 0.99527 to 0.99611, saving model to fake_news_model_fold_5.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.9850 - auc_4: 0.9963 - loss: 0.9424 - precision_4: 0.9880 - recall_4: 0.9819 - val_accuracy: 0.9961 - val_auc_4: 0.9991 - val_loss: 0.2094 - val_precision_4: 0.9978 - val_recall_4: 0.9944 - learning_rate: 5.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m1079/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9868 - auc_4: 0.9970 - loss: 0.2064 - precision_4: 0.9886 - recall_4: 0.9850\n",
            "Epoch 3: val_accuracy did not improve from 0.99611\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - accuracy: 0.9868 - auc_4: 0.9970 - loss: 0.2064 - precision_4: 0.9886 - recall_4: 0.9850 - val_accuracy: 0.9961 - val_auc_4: 0.9980 - val_loss: 0.1403 - val_precision_4: 0.9986 - val_recall_4: 0.9936 - learning_rate: 5.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9902 - auc_4: 0.9975 - loss: 0.1548 - precision_4: 0.9924 - recall_4: 0.9879\n",
            "Epoch 4: val_accuracy did not improve from 0.99611\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 22ms/step - accuracy: 0.9902 - auc_4: 0.9975 - loss: 0.1548 - precision_4: 0.9924 - recall_4: 0.9879 - val_accuracy: 0.9940 - val_auc_4: 0.9996 - val_loss: 0.1408 - val_precision_4: 0.9925 - val_recall_4: 0.9956 - learning_rate: 5.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9888 - auc_4: 0.9972 - loss: 0.1727 - precision_4: 0.9908 - recall_4: 0.9868\n",
            "Epoch 5: val_accuracy did not improve from 0.99611\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - accuracy: 0.9888 - auc_4: 0.9972 - loss: 0.1726 - precision_4: 0.9908 - recall_4: 0.9868 - val_accuracy: 0.9754 - val_auc_4: 0.9992 - val_loss: 0.1901 - val_precision_4: 0.9550 - val_recall_4: 0.9978 - learning_rate: 5.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9881 - auc_4: 0.9974 - loss: 0.1605 - precision_4: 0.9898 - recall_4: 0.9861\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.99611\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 22ms/step - accuracy: 0.9881 - auc_4: 0.9974 - loss: 0.1605 - precision_4: 0.9898 - recall_4: 0.9861 - val_accuracy: 0.9851 - val_auc_4: 0.9983 - val_loss: 0.1429 - val_precision_4: 0.9760 - val_recall_4: 0.9947 - learning_rate: 5.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m1078/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9928 - auc_4: 0.9979 - loss: 0.1137 - precision_4: 0.9954 - recall_4: 0.9903\n",
            "Epoch 7: val_accuracy did not improve from 0.99611\n",
            "\u001b[1m1080/1080\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.9928 - auc_4: 0.9979 - loss: 0.1136 - precision_4: 0.9954 - recall_4: 0.9903 - val_accuracy: 0.9931 - val_auc_4: 0.9993 - val_loss: 0.0877 - val_precision_4: 0.9909 - val_recall_4: 0.9953 - learning_rate: 2.5000e-04\n",
            "Epoch 7: early stopping\n",
            "Restoring model weights from the end of the best epoch: 2.\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - auc_4: 0.9995 - loss: 0.2057 - precision_4: 0.9982 - recall_4: 0.9956\n"
          ]
        }
      ],
      "source": [
        "# Implement k-fold cross-validation\n",
        "n_folds = 5\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "fold_results = []\n",
        "best_val_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_sequences, y)):\n",
        "    print(f\"\\nTraining fold {fold+1}/{n_folds}\")\n",
        "\n",
        "    # Split data\n",
        "    X_train_seq, X_val_seq = X_sequences[train_idx], X_sequences[val_idx]\n",
        "    X_train_features, X_val_features = X_features[train_idx], X_features[val_idx]\n",
        "    y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Build model\n",
        "    model = build_improved_model(vocab_size, embedding_dim, max_length, X_features.shape[1])\n",
        "\n",
        "    # Define callbacks\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=5,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    reduce_lr = ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=3,\n",
        "        min_lr=0.00001,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    model_checkpoint = ModelCheckpoint(\n",
        "        f'fake_news_model_fold_{fold+1}.h5',\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Data augmentation function\n",
        "    def text_augmentation(sequences, labels, augment_ratio=0.2):\n",
        "        augmented_sequences = sequences.copy()\n",
        "        augmented_labels = labels.copy()\n",
        "\n",
        "        # Only augment a portion of the data\n",
        "        aug_indices = np.random.choice(\n",
        "            range(len(sequences)),\n",
        "            size=int(augment_ratio * len(sequences)),\n",
        "            replace=False\n",
        "        )\n",
        "\n",
        "        for idx in aug_indices:\n",
        "            seq = sequences[idx].copy()\n",
        "            # Randomly drop words (set to 0)\n",
        "            drop_indices = np.random.choice(\n",
        "                range(len(seq)),\n",
        "                size=int(0.1 * len(seq)),\n",
        "                replace=False\n",
        "            )\n",
        "            for drop_idx in drop_indices:\n",
        "                if seq[drop_idx] != 0:  # Don't modify padding\n",
        "                    seq[drop_idx] = 0\n",
        "\n",
        "            augmented_sequences = np.vstack([augmented_sequences, [seq]])\n",
        "            augmented_labels = np.append(augmented_labels, labels[idx])\n",
        "\n",
        "        return augmented_sequences, augmented_labels\n",
        "\n",
        "    # Apply data augmentation\n",
        "    X_train_seq_aug, y_train_aug = text_augmentation(X_train_seq, y_train)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        [X_train_seq_aug, np.repeat(X_train_features, len(X_train_seq_aug) // len(X_train_features) + 1, axis=0)[:len(X_train_seq_aug)]],\n",
        "        y_train_aug,\n",
        "        batch_size=32,  # Smaller batch size\n",
        "        epochs=20,\n",
        "        validation_data=([X_val_seq, X_val_features], y_val),\n",
        "        callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model\n",
        "    val_loss, val_accuracy, val_auc, val_precision, val_recall = model.evaluate(\n",
        "        [X_val_seq, X_val_features], y_val, verbose=1\n",
        "    )\n",
        "\n",
        "    fold_results.append({\n",
        "        'fold': fold+1,\n",
        "        'val_loss': val_loss,\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'val_auc': val_auc,\n",
        "        'val_precision': val_precision,\n",
        "        'val_recall': val_recall\n",
        "    })\n",
        "\n",
        "    # Save best model\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        best_model = model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9MgIIcXByCu",
        "outputId": "3db5ad5e-02a0-41a9-c062-160ab0498d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9977 - auc_2: 0.9987 - loss: 0.1403 - precision_2: 0.9998 - recall_2: 0.9956\n",
            "Test Loss: 0.1438\n",
            "Test Accuracy: 0.9969\n",
            "Test AUC: 0.9985\n",
            "Test Precision: 0.9997\n",
            "Test Recall: 0.9942\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Fake News       0.99      1.00      1.00      3597\n",
            "   Real News       1.00      0.99      1.00      3598\n",
            "\n",
            "    accuracy                           1.00      7195\n",
            "   macro avg       1.00      1.00      1.00      7195\n",
            "weighted avg       1.00      1.00      1.00      7195\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a test set\n",
        "visualize_best_model(best_model, X_val_seq, X_val_features, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU48uvR7ByCu",
        "outputId": "908a8e20-3729-440b-d241-fd0bf2790d41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cross-validation results:\n",
            "Fold 1: Accuracy=0.9967, AUC=0.9990\n",
            "Fold 2: Accuracy=0.9967, AUC=0.9989\n",
            "Fold 3: Accuracy=0.9972, AUC=0.9987\n",
            "Fold 4: Accuracy=0.9969, AUC=0.9985\n",
            "Fold 5: Accuracy=0.9961, AUC=0.9991\n",
            "\n",
            "Average Accuracy: 0.9967\n",
            "Average AUC: 0.9988\n",
            "\n",
            "Best model, tokenizer, and vectorizers saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Print cross-validation results\n",
        "print(\"\\nCross-validation results:\")\n",
        "for result in fold_results:\n",
        "    print(f\"Fold {result['fold']}: Accuracy={result['val_accuracy']:.4f}, AUC={result['val_auc']:.4f}\")\n",
        "\n",
        "# Calculate average performance\n",
        "avg_accuracy = np.mean([result['val_accuracy'] for result in fold_results])\n",
        "avg_auc = np.mean([result['val_auc'] for result in fold_results])\n",
        "print(f\"\\nAverage Accuracy: {avg_accuracy:.4f}\")\n",
        "print(f\"Average AUC: {avg_auc:.4f}\")\n",
        "\n",
        "# Save the best model, tokenizer, and vectorizers\n",
        "best_model.save('best_fake_news_detection_model.h5')\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tfidf_vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "print(\"\\nBest model, tokenizer, and vectorizers saved successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eICWbS8GByCu"
      },
      "outputs": [],
      "source": [
        "# Create inference function for testing on new data\n",
        "def predict_fake_news(text, model, tokenizer, tfidf_vectorizer):\n",
        "    # Clean and process text\n",
        "    cleaned_text = clean_text(text)\n",
        "    processed_text = tokenize_and_remove_stopwords(cleaned_text)\n",
        "\n",
        "    # Extract features\n",
        "    features = extract_features(cleaned_text)\n",
        "    features_array = np.array([[\n",
        "        features['sentiment_pos'],\n",
        "        features['sentiment_neg'],\n",
        "        features['sentiment_neu'],\n",
        "        features['sentiment_compound'],\n",
        "        features['readability'],\n",
        "        features['grade_level'],\n",
        "        features['word_count'],\n",
        "        features['avg_word_length'],\n",
        "        features['special_char_ratio']\n",
        "    ]])\n",
        "\n",
        "    # Tokenize and pad\n",
        "    sequence = tokenizer.texts_to_sequences([processed_text])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "    # TF-IDF features\n",
        "    tfidf_features = tfidf_vectorizer.transform([processed_text]).toarray()\n",
        "\n",
        "    # Combine features\n",
        "    combined_features = np.hstack((tfidf_features, features_array))\n",
        "\n",
        "    # Predict\n",
        "    prediction = model.predict([padded_sequence, combined_features])[0][0]\n",
        "    label = \"Real\" if prediction >= 0.5 else \"Fake\"\n",
        "    confidence = prediction if prediction >= 0.5 else 1 - prediction\n",
        "\n",
        "    return {\n",
        "        'label': label,\n",
        "        'confidence': float(confidence),\n",
        "        'raw_score': float(prediction)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPu-NKj_ByCu",
        "outputId": "8a55e311-0e57-4429-8be1-d27fc16304fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
            "\n",
            "Sample prediction: {'label': 'Fake', 'confidence': 0.999121141852811, 'raw_score': 0.0008788581471890211}\n",
            "\n",
            "Model is ready for inference on real-time data!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Test function with sample text\n",
        "sample_text = \"Breaking: Scientists discover new renewable energy source that could revolutionize power generation\"\n",
        "prediction = predict_fake_news(sample_text, best_model, tokenizer, tfidf_vectorizer)\n",
        "print(f\"\\nSample prediction: {prediction}\")\n",
        "\n",
        "print(\"\\nModel is ready for inference on real-time data!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9jn6R6mByCu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}